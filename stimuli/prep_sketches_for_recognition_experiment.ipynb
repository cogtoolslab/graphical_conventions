{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import urllib, cStringIO\n",
    "\n",
    "import pymongo as pm\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import ast\n",
    "\n",
    "from PIL import Image\n",
    "import base64\n",
    "import sys\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "## plotting\n",
    "import matplotlib\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "plt = pyplot\n",
    "import seaborn as sns\n",
    "sns.set_context('talk')\n",
    "sns.set_style('white')\n",
    "\n",
    "## svg rendering \n",
    "# import ast\n",
    "# from svgpathtools import parse_path, wsvg, svg2paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### paths etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# directory & file hierarchy\n",
    "proj_dir = os.path.abspath('../')\n",
    "stimulus_dir = os.getcwd()\n",
    "analysis_dir = os.path.join(proj_dir,'analysis')\n",
    "results_dir = os.path.join(proj_dir,'results')\n",
    "plot_dir = os.path.join(results_dir,'plots')\n",
    "csv_dir = os.path.join(results_dir,'csv')\n",
    "exp_dir = os.path.abspath(os.path.join(proj_dir,'experiments'))\n",
    "sketch_dir = os.path.abspath(os.path.join(proj_dir,'sketches'))\n",
    "\n",
    "## add helpers to python path\n",
    "if os.path.join(proj_dir,'analysis','python') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir,'analysis','python'))\n",
    "    \n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "    \n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)   \n",
    "    \n",
    "if not os.path.exists(csv_dir):\n",
    "    os.makedirs(csv_dir)       \n",
    "    \n",
    "# Assign variables within imported analysis helpers\n",
    "import df_generation_helpers as h\n",
    "if sys.version_info[0]>=3:\n",
    "    from importlib import reload\n",
    "reload(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load in group data csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_group_data = os.path.join(results_dir,'graphical_conventions.csv')\n",
    "X = pd.read_csv(path_to_group_data)\n",
    "\n",
    "## remove unnecessary columns\n",
    "if 'Unnamed: 0' in X.columns:\n",
    "    X = X.drop(labels=['Unnamed: 0','row_index'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### render sketches using svg data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import svg_rendering_helpers as srh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## extract sketch identifying info\n",
    "gseries = X['gameID'].map(str)\n",
    "nseries = X['trialNum'].map(str).apply(lambda x: x.zfill(2))\n",
    "rseries = X['repetition'].map(str).apply(lambda x: x.zfill(2))\n",
    "tseries = X['target'].map(str)\n",
    "\n",
    "## build list of image filenames\n",
    "fname_list = ['{}_{}_{}'.format(i,j,k) for (i,j,k) in zip(gseries,rseries,tseries)]\n",
    "\n",
    "## convert svg string strings into svg string list\n",
    "svg_string_list = [ast.literal_eval(i) for i in X.svgString.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## render out svg & convert to png\n",
    "reload(srh)\n",
    "reallyRun = 0\n",
    "if reallyRun:\n",
    "    for this_fname,this_svg in zip(fname_list,svg_string_list):    \n",
    "        srh.render_svg(this_svg,base_dir=sketch_dir,out_fname= '{}.svg'.format(this_fname))    \n",
    "        clear_output(wait=True)\n",
    "        \n",
    "    ## get svg path list for rendered out svg\n",
    "    svg_paths = srh.generate_svg_path_list(os.path.join(sketch_dir,'svg'))    \n",
    "    \n",
    "    ## convert all svg to png\n",
    "    srh.svg_to_png(svg_paths,base_dir=sketch_dir)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### upload stims to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import boto\n",
    "bucket_name = 'graphical-conventions-sketches'\n",
    "path_to_png = os.path.join(sketch_dir,'png')\n",
    "runThis = 0\n",
    "if runThis:\n",
    "    conn = boto.connect_s3()\n",
    "    b = conn.create_bucket(bucket_name) ### if bucket already exists, then get_bucket, else create_bucket\n",
    "    for ind,im in enumerate(os.listdir(path_to_png)):\n",
    "        if im[-3:]=='png':\n",
    "            print ind, im\n",
    "            k = b.new_key(im)\n",
    "            k.set_contents_from_filename(os.path.join(path_to_png,im))\n",
    "            k.set_acl('public-read')\n",
    "            clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build stimulus dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FYI**: `recog_id` refers to a unique session type in the recognition experiment, where all the sketches are guaranteed to have been generated by different participants in different repetition cycles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## sanity checks\n",
    "num_trials_per_recog_session = 10\n",
    "assert np.unique([sum(X['recog_id']==i) for i in np.unique(X['recog_id'])])[0]==num_trials_per_recog_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## subset columns that are going to be in the stimuli database for the recognition experiment\n",
    "## basically, retain everything except for bigger pieces of data, e.g., png and svgString\n",
    "X2 = X.drop(labels=['png','svgString'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Meta = []\n",
    "for name,group in X2.groupby(['recog_id']):\n",
    "    print '{}'.format(name)\n",
    "    Stimdict = {}   ## initialize this to convert the list of trial dicts to a dict of dicts, with gameID as the key to each trial  \n",
    "    stimdict = group.to_dict(orient='records')\n",
    "    for trial in stimdict:\n",
    "        target_shapenet = trial['target_shapenet']\n",
    "        distractors_shapenet = ast.literal_eval(trial['distractors_shapenet'])\n",
    "        distractors = ast.literal_eval(trial['distractors'])\n",
    "        trial['target'] = {'shapenetid':target_shapenet, 'objectname': trial['target'], 'url': 'https://s3.amazonaws.com/shapenet-graphical-conventions/' + target_shapenet+'.png'}\n",
    "        trial['distractor1'] = {'shapenetid':distractors_shapenet['distractor1'], 'objectname': distractors['distractor1'], 'url': 'https://s3.amazonaws.com/shapenet-graphical-conventions/' + distractors_shapenet['distractor1'] + '.png'}\n",
    "        trial['distractor2'] = {'shapenetid':distractors_shapenet['distractor2'], 'objectname': distractors['distractor2'], 'url': 'https://s3.amazonaws.com/shapenet-graphical-conventions/' + distractors_shapenet['distractor2'] + '.png'}\n",
    "        trial['distractor3'] = {'shapenetid':distractors_shapenet['distractor3'], 'objectname': distractors['distractor3'], 'url': 'https://s3.amazonaws.com/shapenet-graphical-conventions/' + distractors_shapenet['distractor3'] + '.png'}\n",
    "        trial['sketch'] = str(trial['gameID']) + '_' + str( trial['repetition']).zfill(2) + '_' + str(trial['target']['objectname'])\n",
    "        trial['sketch_url'] = 'https://s3.amazonaws.com/graphical-conventions-sketches/' + trial['sketch'] + '.png'\n",
    "    Stimdict['meta'] = stimdict\n",
    "    Stimdict['recog_id'] = np.unique(group['recog_id'].values)[0]  \n",
    "    Stimdict['games'] = []\n",
    "    Meta.append(Stimdict)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### upload to mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_name = 'graphical_conventions_sketches'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## write out metadata to json file\n",
    "## for example:\n",
    "# stimdict = meta.to_dict(orient='records')\n",
    "# stimdict\n",
    "import json\n",
    "with open('{}.js'.format(dataset_name), 'w') as fout:\n",
    "     json.dump(Meta, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### next todo is to upload this JSON to initialize the new stimulus collection\n",
    "print('next todo is to upload this JSON to initialize the new stimulus collection...')\n",
    "import json\n",
    "J = json.loads(open('{}.js'.format(dataset_name),mode='ru').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'dataset_name: {}'.format(dataset_name)\n",
    "print 'Length of J is: {}'.format(len(J))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set vars \n",
    "auth = pd.read_csv('.auth.txt', header = None) # this auth.txt file contains the password for the sketchloop user\n",
    "pswd = auth.values[0][0]\n",
    "user = 'sketchloop'\n",
    "host = 'rxdhawkins.me' ## cocolab ip address\n",
    "\n",
    "# have to fix this to be able to analyze from local\n",
    "conn = pm.MongoClient('mongodb://sketchloop:' + pswd + '@127.0.0.1')\n",
    "db = conn['stimuli']\n",
    "coll = db[dataset_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## actually add data now to the database\n",
    "reallyRun = 1\n",
    "if reallyRun:\n",
    "    for (i,j) in enumerate(J):\n",
    "        if i%10==0:\n",
    "            print ('%d of %d uploaded ...' % (i,len(J)))\n",
    "            clear_output(wait=True)\n",
    "        coll.insert_one(j)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'We have {} records in the database.'.format(coll.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
