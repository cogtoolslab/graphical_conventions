{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import urllib, cStringIO\n",
    "\n",
    "import pymongo as pm\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import ast\n",
    "\n",
    "from PIL import Image\n",
    "import base64\n",
    "import sys\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "## plotting\n",
    "import matplotlib\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "plt = pyplot\n",
    "import seaborn as sns\n",
    "sns.set_context('talk')\n",
    "sns.set_style('white')\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "## svg rendering \n",
    "# import ast\n",
    "# from svgpathtools import parse_path, wsvg, svg2paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### paths etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'df_generation_helpers' from '/Users/judithfan/graphical_conventions/analysis/python/df_generation_helpers.pyc'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# directory & file hierarchy\n",
    "proj_dir = os.path.abspath('../')\n",
    "stimulus_dir = os.getcwd()\n",
    "analysis_dir = os.path.join(proj_dir,'analysis')\n",
    "results_dir = os.path.join(proj_dir,'results')\n",
    "plot_dir = os.path.join(results_dir,'plots')\n",
    "csv_dir = os.path.join(results_dir,'csv')\n",
    "exp_dir = os.path.abspath(os.path.join(proj_dir,'experiments'))\n",
    "sketch_dir = os.path.abspath(os.path.join(proj_dir,'sketches'))\n",
    "\n",
    "## add helpers to python path\n",
    "if os.path.join(proj_dir,'analysis','python') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir,'analysis','python'))\n",
    "    \n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "    \n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)   \n",
    "    \n",
    "if not os.path.exists(csv_dir):\n",
    "    os.makedirs(csv_dir)       \n",
    "    \n",
    "# Assign variables within imported analysis helpers\n",
    "import df_generation_helpers as h\n",
    "if sys.version_info[0]>=3:\n",
    "    from importlib import reload\n",
    "reload(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load in group data csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe initially contained 65 unique games. Now contains 65 games.\n",
      "There were 0 outlier games: []. Now filtered.\n"
     ]
    }
   ],
   "source": [
    "## name of experiment\n",
    "this_experiment = 'refgame2.0'\n",
    "\n",
    "## update name of sketch dir so sketches from each experiment are nested appropriately\n",
    "sketch_dir = os.path.abspath(os.path.join(proj_dir,'sketches',this_experiment))\n",
    "\n",
    "## extract appropriate filename suffix based on experiment name\n",
    "experiment_dict = {'refgame1.2':'run3run4','refgame2.0':'run5_submitButton'}\n",
    "exp_ext = experiment_dict[this_experiment]\n",
    "\n",
    "path_to_group_data = os.path.join(csv_dir,'graphical_conventions_group_data_{}.csv'.format(exp_ext))\n",
    "X = pd.read_csv(path_to_group_data)\n",
    "\n",
    "## handle missing data (missing draw duration measurements)\n",
    "X = h.preprocess_dataframe(X)\n",
    "\n",
    "## remove unnecessary columns\n",
    "if 'Unnamed: 0' in X.columns:\n",
    "    X = X.drop(labels=['Unnamed: 0','row_index'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### render sketches using svg data (can be skipped if already rendered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import svg_rendering_helpers as srh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## extract sketch identifying info\n",
    "gseries = X['gameID'].map(str)\n",
    "nseries = X['trialNum'].map(str).apply(lambda x: x.zfill(2))\n",
    "rseries = X['repetition'].map(str).apply(lambda x: x.zfill(2))\n",
    "tseries = X['target'].map(str)\n",
    "\n",
    "## build list of image filenames\n",
    "fname_list = ['{}_{}_{}'.format(i,j,k) for (i,j,k) in zip(gseries,rseries,tseries)]\n",
    "\n",
    "## convert svg string strings into svg string list\n",
    "svg_string_list = [ast.literal_eval(i) for i in X.svgString.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert /Users/judithfan/graphical_conventions/sketches/refgame2.0/svg/9834-afb725fc-5a68-4c1b-a6f1-5f45c61e3776_07_waiting_05.svg /Users/judithfan/graphical_conventions/sketches/refgame2.0/png/9834-afb725fc-5a68-4c1b-a6f1-5f45c61e3776_07_waiting_05.png\n"
     ]
    }
   ],
   "source": [
    "## render out svg & convert to png\n",
    "reload(srh)\n",
    "reallyRun = 1\n",
    "if reallyRun:\n",
    "    for this_fname,this_svg in zip(fname_list,svg_string_list):    \n",
    "        srh.render_svg(this_svg,base_dir=sketch_dir,out_fname= '{}.svg'.format(this_fname))    \n",
    "        clear_output(wait=True)\n",
    "        \n",
    "    ## get svg path list for rendered out svg\n",
    "    svg_paths = srh.generate_svg_path_list(os.path.join(sketch_dir,'svg'))    \n",
    "    \n",
    "    ## convert all svg to png\n",
    "    srh.svg_to_png(svg_paths,base_dir=sketch_dir)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### upload stims to s3 (can be skipped if already rendered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2599 9834-afb725fc-5a68-4c1b-a6f1-5f45c61e3776_07_waiting_05.png\n"
     ]
    }
   ],
   "source": [
    "import boto\n",
    "bucket_name = 'graphical-conventions-sketches'\n",
    "path_to_png = os.path.join(sketch_dir,'png')\n",
    "runThis = 0\n",
    "if runThis:\n",
    "    conn = boto.connect_s3()\n",
    "    b = conn.create_bucket(bucket_name) ### if bucket already exists, then get_bucket, else create_bucket\n",
    "    for ind,im in enumerate(os.listdir(path_to_png)):\n",
    "        if im[-3:]=='png':\n",
    "            print ind, im\n",
    "            k = b.new_key(im)\n",
    "            k.set_contents_from_filename(os.path.join(path_to_png,im))\n",
    "            k.set_acl('public-read')\n",
    "            clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build stimulus dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FYI**: `recog_id` refers to a unique session type in the recognition experiment, where all the sketches are guaranteed to have been generated by different participants in different repetition cycles \n",
    "\n",
    "#### from refgame1.2 (run3run4)\n",
    "- `Meta_yoked` : 67 bundles of 40 trials (each bundle corresponding to 1 refgame)\n",
    "- `Meta_scrambled` : 67 bundles of 40 trials (the four trials of each repetition coming from different games)\n",
    "- `Meta` : 268 bundles of 10 trials (each trial corresponding to some repetition (8 repeated + 2 control))\n",
    "\n",
    "#### from refgame2.0  (run5)\n",
    "- `Meta_yoked_refgame2.0` : 67 bundles of 40 trials (each bundle corresponding to 1 refgame)\n",
    "- `Meta_scrambled_refgame2.0` : 67 bundles of 40 trials (the four trials of each repetition coming from different games)\n",
    "- `Meta_refgame2.0` : 268 bundles of 10 trials (each trial corresponding to some repetition (8 repeated + 2 control))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## sanity checks\n",
    "num_trials_per_recog_session = 10\n",
    "assert np.unique([sum(X['recog_id']==i) for i in np.unique(X['recog_id'])])[0]==num_trials_per_recog_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## subset columns that are going to be in the stimuli database for the recognition experiment\n",
    "## basically, retain everything except for bigger pieces of data, e.g., png and svgString\n",
    "X2 = X.drop(labels=['png','svgString'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### yoked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do we only want to upload what is remaining for the yoked? False\n",
      "Do not subset, and assign copy of old dataframe variable to new variable.\n"
     ]
    }
   ],
   "source": [
    "## do we only want to upload what is remaining for the yoked?\n",
    "upload_targeted = False\n",
    "print 'Do we only want to upload what is remaining for the yoked? {}'.format(upload_targeted)\n",
    "\n",
    "## load in remaining gameIDs to run in yoked\n",
    "remaining_gameIDs = pd.read_csv('orig_gameIDs_remaining_yoked.csv')\n",
    "remaining_gameIDs = remaining_gameIDs.gameID.values\n",
    "\n",
    "## subset the whole dataframe by the gameIDs that remain to be run\n",
    "if upload_targeted:\n",
    "    _X2 = X2[X2['gameID'].isin(remaining_gameIDs)]\n",
    "    print 'Subsetting by remaining gameIDs and assigning to new dataframe variable.'\n",
    "else:\n",
    "    _X2 = X2\n",
    "    print 'Do not subset, and assign copy of old dataframe variable to new variable.'    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9834-afb725fc-5a68-4c1b-a6f1-5f45c61e3776\n"
     ]
    }
   ],
   "source": [
    "Meta_yoked = []\n",
    "for name, group in _X2.groupby(['gameID']):\n",
    "    print '{}'.format(name)\n",
    "    Stimdict = {}\n",
    "    stimdict = group.to_dict(orient='records')\n",
    "    for trial in stimdict:\n",
    "        target_shapenet = trial['target_shapenet']\n",
    "        distractors_shapenet = ast.literal_eval(trial['distractors_shapenet'])\n",
    "        distractors = ast.literal_eval(trial['distractors'])\n",
    "        trial['target'] = {'shapenetid':target_shapenet, 'objectname': trial['target'], 'url': 'https://s3.amazonaws.com/shapenet-graphical-conventions/' + target_shapenet+'.png'}\n",
    "        trial['distractor1'] = {'shapenetid':distractors_shapenet['distractor1'], 'objectname': distractors['distractor1'], 'url': 'https://s3.amazonaws.com/shapenet-graphical-conventions/' + distractors_shapenet['distractor1'] + '.png'}\n",
    "        trial['distractor2'] = {'shapenetid':distractors_shapenet['distractor2'], 'objectname': distractors['distractor2'], 'url': 'https://s3.amazonaws.com/shapenet-graphical-conventions/' + distractors_shapenet['distractor2'] + '.png'}\n",
    "        trial['distractor3'] = {'shapenetid':distractors_shapenet['distractor3'], 'objectname': distractors['distractor3'], 'url': 'https://s3.amazonaws.com/shapenet-graphical-conventions/' + distractors_shapenet['distractor3'] + '.png'}\n",
    "        trial['sketch'] = str(trial['gameID']) + '_' + str( trial['repetition']).zfill(2) + '_' + str(trial['target']['objectname'])\n",
    "        trial['sketch_url'] = 'https://s3.amazonaws.com/graphical-conventions-sketches/' + trial['sketch'] + '.png'\n",
    "        trial['orig_gameID'] = trial.pop('gameID') ## rename gameID as orig_gameID        \n",
    "    Stimdict['meta'] = stimdict \n",
    "    Stimdict['games'] = []\n",
    "    Stimdict['gameID'] = np.unique(group['gameID'].values)[0]  \n",
    "    Meta_yoked.append(Stimdict)\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "## ensure that number of gameIDs associated with yoked is 1\n",
    "assert len(Counter([i['orig_gameID'] for i in Meta_yoked[0]['meta']]).keys())==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sequence-scrambled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do we only want to upload what is remaining for the scrambled40? False\n",
      "There are 0 remaining grouped recog ids to run.\n",
      "Do not subset, and assign copy of old dataframe variable to new variable.\n"
     ]
    }
   ],
   "source": [
    "## do we only want to upload what is remaining for the scrambled40?\n",
    "upload_targeted = False\n",
    "print 'Do we only want to upload what is remaining for the scrambled40? {}'.format(upload_targeted)\n",
    "\n",
    "## create new column called grouped_recog_id\n",
    "X2['grouped_recog_id'] = np.int64(X2['recog_id']/4)\n",
    "\n",
    "## load in remaining gameIDs to run in scrambled40\n",
    "remaining_ids = pd.read_csv('grouped_recog_ids_remaining_scrambled40.csv')\n",
    "remaining_ids = remaining_ids.grouped_recog_id.values\n",
    "print 'There are {} remaining grouped recog ids to run.'.format(len(remaining_ids))\n",
    "\n",
    "## subset the whole dataframe by the gameIDs that remain to be run\n",
    "if upload_targeted:\n",
    "    __X2 = X2[X2['grouped_recog_id'].isin(remaining_ids)]\n",
    "    print 'Subsetting by remaining gameIDs and assigning to new dataframe variable.'\n",
    "else:\n",
    "    __X2 = X2\n",
    "    print 'Do not subset, and assign copy of old dataframe variable to new variable.'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "Meta_scrambled = []\n",
    "for name, group in __X2.groupby(['grouped_recog_id']):\n",
    "    print '{}'.format(name)\n",
    "    Stimdict = {}\n",
    "    stimdict = group.to_dict(orient='records')\n",
    "    for trial in stimdict:\n",
    "        target_shapenet = trial['target_shapenet']\n",
    "        distractors_shapenet = ast.literal_eval(trial['distractors_shapenet'])\n",
    "        distractors = ast.literal_eval(trial['distractors'])\n",
    "        trial['target'] = {'shapenetid':target_shapenet, 'objectname': trial['target'], 'url': 'https://s3.amazonaws.com/shapenet-graphical-conventions/' + target_shapenet+'.png'}\n",
    "        trial['distractor1'] = {'shapenetid':distractors_shapenet['distractor1'], 'objectname': distractors['distractor1'], 'url': 'https://s3.amazonaws.com/shapenet-graphical-conventions/' + distractors_shapenet['distractor1'] + '.png'}\n",
    "        trial['distractor2'] = {'shapenetid':distractors_shapenet['distractor2'], 'objectname': distractors['distractor2'], 'url': 'https://s3.amazonaws.com/shapenet-graphical-conventions/' + distractors_shapenet['distractor2'] + '.png'}\n",
    "        trial['distractor3'] = {'shapenetid':distractors_shapenet['distractor3'], 'objectname': distractors['distractor3'], 'url': 'https://s3.amazonaws.com/shapenet-graphical-conventions/' + distractors_shapenet['distractor3'] + '.png'}\n",
    "        trial['sketch'] = str(trial['gameID']) + '_' + str( trial['repetition']).zfill(2) + '_' + str(trial['target']['objectname'])\n",
    "        trial['sketch_url'] = 'https://s3.amazonaws.com/graphical-conventions-sketches/' + trial['sketch'] + '.png'\n",
    "        trial['orig_gameID'] = trial.pop('gameID') ## rename gameID as orig_gameID\n",
    "    stimdict_sorted = sorted(stimdict, key=lambda k: k['trialNum']) ## sorts dictionary by trialNum inline\n",
    "    Stimdict['meta'] = stimdict_sorted\n",
    "    Stimdict['recog_id'] = np.unique(group['grouped_recog_id'].values)[0]  \n",
    "    Stimdict['games'] = []\n",
    "    Meta_scrambled.append(Stimdict)\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "## make sure that there 4 reps per gameID, and 10 unique gameID's\n",
    "assert np.unique(Counter([i['orig_gameID'] for i in Meta_scrambled[0]['meta']]).values())[0]==4\n",
    "assert len(np.unique(Counter([i['orig_gameID'] for i in Meta_scrambled[0]['meta']]).keys()))==10    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(__X2['grouped_recog_id'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scrambled10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259\n"
     ]
    }
   ],
   "source": [
    "# original recog id \n",
    "Meta = []\n",
    "for name,group in X2.groupby(['recog_id']):\n",
    "    print '{}'.format(name)\n",
    "    Stimdict = {}   ## initialize this to convert the list of trial dicts to a dict of dicts, with gameID as the key to each trial  \n",
    "    stimdict = group.to_dict(orient='records')\n",
    "    for trial in stimdict:\n",
    "        target_shapenet = trial['target_shapenet']\n",
    "        distractors_shapenet = ast.literal_eval(trial['distractors_shapenet'])\n",
    "        distractors = ast.literal_eval(trial['distractors'])\n",
    "        trial['target'] = {'shapenetid':target_shapenet, 'objectname': trial['target'], 'url': 'https://s3.amazonaws.com/shapenet-graphical-conventions/' + target_shapenet+'.png'}\n",
    "        trial['distractor1'] = {'shapenetid':distractors_shapenet['distractor1'], 'objectname': distractors['distractor1'], 'url': 'https://s3.amazonaws.com/shapenet-graphical-conventions/' + distractors_shapenet['distractor1'] + '.png'}\n",
    "        trial['distractor2'] = {'shapenetid':distractors_shapenet['distractor2'], 'objectname': distractors['distractor2'], 'url': 'https://s3.amazonaws.com/shapenet-graphical-conventions/' + distractors_shapenet['distractor2'] + '.png'}\n",
    "        trial['distractor3'] = {'shapenetid':distractors_shapenet['distractor3'], 'objectname': distractors['distractor3'], 'url': 'https://s3.amazonaws.com/shapenet-graphical-conventions/' + distractors_shapenet['distractor3'] + '.png'}\n",
    "        trial['sketch'] = str(trial['gameID']) + '_' + str( trial['repetition']).zfill(2) + '_' + str(trial['target']['objectname'])\n",
    "        trial['sketch_url'] = 'https://s3.amazonaws.com/graphical-conventions-sketches/' + trial['sketch'] + '.png'\n",
    "        trial['orig_gameID'] = trial.pop('gameID') ## rename gameID as orig_gameID\n",
    "    Stimdict['meta'] = stimdict\n",
    "    Stimdict['recog_id'] = np.unique(group['recog_id'].values)[0]  \n",
    "    Stimdict['games'] = []\n",
    "    Meta.append(Stimdict)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### upload to mongo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FYI**: `recog_id` refers to a unique session type in the recognition experiment, where all the sketches are guaranteed to have been generated by different participants in different repetition cycles \n",
    "\n",
    "`graphical_conventions_sketches_yoked` : 67 bundles of 40 trials (each bundle corresponding to 1 refgame)\n",
    "\n",
    "`graphical_conventions_sketches_scrambled40` : 67 bundles of 40 trials (the four trials of each repetition coming from different games)\n",
    "\n",
    "`graphical_conventions_sketches_scrambled10` : 268 bundles of 10 trials (each trial corresponding to some repetition (8 repeated + 2 control))\n",
    "\n",
    "Each coll also has a + '_dev' version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## define dataset names for each \n",
    "yoked = 'graphical_conventions_sketches_yoked_{}'.format(this_experiment)\n",
    "scrambled40 = 'graphical_conventions_sketches_scrambled40_{}'.format(this_experiment)\n",
    "scrambled10 = 'graphical_conventions_sketches_scrambled10_{}'.format(this_experiment)\n",
    "\n",
    "if upload_targeted:\n",
    "    yoked = 'graphical_conventions_sketches_yoked_remaining'.format(this_experiment)\n",
    "    scrambled40 = 'graphical_conventions_sketches_scrambled40_remaining'.format(this_experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## write out metadata to json file\n",
    "## for example:\n",
    "# stimdict = meta.to_dict(orient='records')\n",
    "# stimdict\n",
    "import json\n",
    "with open('{}_{}.js'.format(yoked,this_experiment), 'w') as fout:\n",
    "     json.dump(Meta_yoked, fout)\n",
    "with open('{}_{}.js'.format(scrambled40,this_experiment), 'w') as fout:\n",
    "     json.dump(Meta_scrambled, fout)\n",
    "with open('{}_{}.js'.format(scrambled10,this_experiment), 'w') as fout:\n",
    "     json.dump(Meta, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### next todo is to upload this JSON to initialize the new stimulus collection\n",
    "import json\n",
    "J_yoked = json.loads(open('{}_{}.js'.format(yoked,this_experiment),mode='ru').read())\n",
    "J_scrambled40 = json.loads(open('{}_{}.js'.format(scrambled40,this_experiment),mode='ru').read())\n",
    "J_scrambled10 = json.loads(open('{}_{}.js'.format(scrambled10,this_experiment),mode='ru').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_name: graphical_conventions_sketches_yoked_refgame2.0\n",
      "Length of J is: 65\n",
      "dataset_name: graphical_conventions_sketches_scrambled40_refgame2.0\n",
      "Length of J is: 65\n",
      "dataset_name: graphical_conventions_sketches_scrambled10_refgame2.0\n",
      "Length of J is: 260\n"
     ]
    }
   ],
   "source": [
    "print 'dataset_name: {}'.format(yoked)\n",
    "print 'Length of J is: {}'.format(len(J_yoked))\n",
    "print 'dataset_name: {}'.format(scrambled40)\n",
    "print 'Length of J is: {}'.format(len(J_scrambled40))\n",
    "print 'dataset_name: {}'.format(scrambled10)\n",
    "print 'Length of J is: {}'.format(len(J_scrambled10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set vars \n",
    "auth = pd.read_csv('.auth.txt', header = None) # this auth.txt file contains the password for the sketchloop user\n",
    "pswd = auth.values[0][0]\n",
    "user = 'sketchloop'\n",
    "host = 'stanford-cogsci.org' ## cocolab ip address\n",
    "\n",
    "# have to fix this to be able to analyze from local\n",
    "conn = pm.MongoClient('mongodb://sketchloop:' + pswd + '@127.0.0.1')\n",
    "db = conn['stimuli']\n",
    "coll_yoked = db[yoked]\n",
    "coll_scrambled40 = db[scrambled40]\n",
    "yoked_dev = yoked + '_dev'\n",
    "scrambled40_dev = scrambled40 + '_dev'\n",
    "scrambled10_dev = scrambled10 + '_dev'\n",
    "coll_yoked_dev = db[yoked_dev]\n",
    "coll_scrambled40_dev = db[scrambled40_dev]\n",
    "coll_scrambled10_dev = db[scrambled10_dev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 of 65 uploaded ...\n"
     ]
    }
   ],
   "source": [
    "## actually add data now to the database\n",
    "## recommended sequence: J_yoked, J_yoked_dev, J_scrambled40, J_scrambled40_dev\n",
    "reallyRun = 0\n",
    "if reallyRun:\n",
    "    Y = zip([J_yoked, J_yoked, J_scrambled40, J_scrambled40],\\\n",
    "            [coll_yoked, coll_yoked_dev, coll_scrambled40, coll_scrambled40_dev])\n",
    "    for i,y in enumerate(Y):\n",
    "        J = y[0]\n",
    "        coll = y[1]\n",
    "        for (i,j) in enumerate(J):\n",
    "            if i%1==0:\n",
    "                print ('%d of %d uploaded ...' % (i,len(J)))\n",
    "                clear_output(wait=True)\n",
    "            coll.insert_one(j)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 65 records in the database.\n"
     ]
    }
   ],
   "source": [
    "print 'We have {} records in the database.'.format(coll.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# assert db['graphical_conventions_sketches_yoked_remaining_{}'.format(this_experiment)].count()==len(J_yoked)\n",
    "assert db['graphical_conventions_sketches_yoked_{}'.format(this_experiment)].count()==65\n",
    "assert db['graphical_conventions_sketches_yoked_{}_dev'.format(this_experiment)].count()==65\n",
    "# assert db['graphical_conventions_sketches_scrambled40_remaining_{}'.format(this_experiment)].count()==len(J_scrambled40)\n",
    "assert db['graphical_conventions_sketches_scrambled40_{}_dev'.format(this_experiment)].count()==65\n",
    "assert db['graphical_conventions_sketches_scrambled40_{}'.format(this_experiment)].count()==65\n",
    "# assert db['graphical_conventions_sketches_scrambled10_{}_dev'.format(this_experiment)].count()==260\n",
    "# assert db['graphical_conventions_sketches_scrambled10_{}'.format(this_experiment)].count()==260"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'chairs140',\n",
       " u'chairs1k',\n",
       " u'chairs1k_archived',\n",
       " u'chairs1k_expansion_only',\n",
       " u'chairs2k',\n",
       " u'chairs2k_expansion_only',\n",
       " u'graphical_conventions_sketches_scrambled10',\n",
       " u'graphical_conventions_sketches_scrambled10_dev',\n",
       " u'graphical_conventions_sketches_scrambled40',\n",
       " u'graphical_conventions_sketches_scrambled40_dev',\n",
       " u'graphical_conventions_sketches_scrambled40_refgame2.0',\n",
       " u'graphical_conventions_sketches_scrambled40_refgame2.0_dev',\n",
       " u'graphical_conventions_sketches_scrambled40_remaining',\n",
       " u'graphical_conventions_sketches_yoked',\n",
       " u'graphical_conventions_sketches_yoked_dev',\n",
       " u'graphical_conventions_sketches_yoked_refgame2.0',\n",
       " u'graphical_conventions_sketches_yoked_refgame2.0_dev',\n",
       " u'graphical_conventions_sketches_yoked_remaining',\n",
       " u'kiddraw_tracing_eval',\n",
       " u'kiddraw_tracing_eval2',\n",
       " u'kiddraw_tracing_eval_dev',\n",
       " u'kiddraw_tracing_eval_square_copy',\n",
       " u'kiddraw_tracing_eval_square_copy_dev',\n",
       " u'photodraw2',\n",
       " u'shapenet_chairs_speaker_eval',\n",
       " u'sketchpad_basic_pilot2_sketches',\n",
       " u'svg_annotation_demo',\n",
       " u'svg_annotation_sketchpad_basic',\n",
       " u'svg_annotation_sketchpad_basic_allcats',\n",
       " u'svg_annotation_sketchpad_basic_allcats_dev',\n",
       " u'svg_annotation_sketchpad_basic_chairs',\n",
       " u'svg_annotation_sketchpad_basic_chairs4',\n",
       " u'svg_annotation_sketchpad_basic_chairs4_dev',\n",
       " u'svg_annotation_sketchpad_basic_chairs_dev']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(db.collection_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db['graphical_conventions_sketches_yoked'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
