{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import urllib, cStringIO\n",
    "\n",
    "import pymongo as pm\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "from PIL import Image\n",
    "import base64\n",
    "import sys\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "plt = pyplot\n",
    "import seaborn as sns\n",
    "sns.set_context('talk')\n",
    "sns.set_style('white')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# directory & file hierarchy\n",
    "proj_dir = os.path.abspath('../../..')\n",
    "analysis_dir = os.getcwd()\n",
    "results_dir = os.path.join(proj_dir,'results')\n",
    "plot_dir = os.path.join(results_dir,'plots')\n",
    "csv_dir = os.path.join(results_dir,'csv')\n",
    "exp_dir = os.path.abspath(os.path.join(proj_dir,'experiments'))\n",
    "sketch_dir = os.path.abspath(os.path.join(proj_dir,'sketches'))\n",
    "\n",
    "## add helpers to python path\n",
    "if os.path.join(proj_dir,'analysis','python') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir,'analysis','python'))\n",
    "    \n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "    \n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)   \n",
    "    \n",
    "if not os.path.exists(csv_dir):\n",
    "    os.makedirs(csv_dir)       \n",
    "    \n",
    "# Assign variables within imported analysis helpers\n",
    "import df_generation_helpers as h\n",
    "if sys.version_info[0]>=3:\n",
    "    from importlib import reload\n",
    "reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set vars \n",
    "auth = pd.read_csv('auth.txt', header = None) # this auth.txt file contains the password for the sketchloop user\n",
    "pswd = auth.values[0][0]\n",
    "user = 'sketchloop'\n",
    "host = 'rxdhawkins.me' ## cocolab ip address\n",
    "\n",
    "# have to fix this to be able to analyze from local\n",
    "import pymongo as pm\n",
    "conn = pm.MongoClient('mongodb://sketchloop:' + pswd + '@127.0.0.1')\n",
    "db = conn['3dObjects']\n",
    "coll = db['graphical_conventions']\n",
    "\n",
    "# which iteration name should we use?\n",
    "iterationName1 = 'run3_size4_waiting'\n",
    "iterationName2 = 'run4_generalization'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## list of researcher mturk worker ID's to ignore\n",
    "jefan = ['A1MMCS8S8CTWKU','A1MMCS8S8CTWKV','A1MMCS8S8CTWKS']\n",
    "hawkrobe = ['A1BOIDKD33QSDK']\n",
    "megsano = ['A1DVQQLVZR7W6I']\n",
    "researchers = jefan + hawkrobe + megsano "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## run 3 - get total number of stroke and clickedObj events in the collection as a whole\n",
    "S1 = coll.find({ '$and': [{'iterationName':iterationName1}, {'eventType': 'stroke'}]}).sort('time')\n",
    "C1 = coll.find({ '$and': [{'iterationName':iterationName1}, {'eventType': 'clickedObj'}]}).sort('time')\n",
    "\n",
    "## run 4 - get total number of stroke and clickedObj events in the collection as a whole\n",
    "S2 = coll.find({ '$and': [{'iterationName':iterationName2}, {'eventType': 'stroke'}]}).sort('time')\n",
    "C2 = coll.find({ '$and': [{'iterationName':iterationName2}, {'eventType': 'clickedObj'}]}).sort('time')\n",
    "\n",
    "print str(S1.count() + S2.count()) + ' stroke records in the database.'\n",
    "print str(C1.count() + S2.count()) + ' clickedObj records in the database.' # previously 722 so 882 ideally "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate group dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "reload(h)\n",
    "## get list of all candidate games\n",
    "games = coll.distinct('gameid')\n",
    "\n",
    "## get list of complete and valid games\n",
    "run3_complete_games = h.get_complete_and_valid_games(games,coll,iterationName1,researchers=researchers, tolerate_undefined_worker=False)\n",
    "run4_complete_games = h.get_complete_and_valid_games(games,coll,iterationName2,researchers=researchers, tolerate_undefined_worker=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reload(h)\n",
    "## generate actual dataframe and get only valid games (filtering out games with low accuracy, timeouts)\n",
    "D_run3 = h.generate_dataframe(coll, run3_complete_games, iterationName1, results_dir)\n",
    "D_run4 = h.generate_dataframe(coll, run4_complete_games, iterationName2, results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## filtering outliers \n",
    "D_run3_filtered = h.filter_crazies(D_run3, 'numStrokes')\n",
    "D_run3_filtered = h.filter_crazies(D_run3_filtered, 'numCurvesPerSketch')\n",
    "D_run4_filtered = h.filter_crazies(D_run4, 'numStrokes')\n",
    "D_run4_filtered = h.filter_crazies(D_run4_filtered, 'numCurvesPerSketch')\n",
    "\n",
    "# filter out incorrect trials \n",
    "D_run3_correct = D_run3_filtered[D_run3_filtered['outcome'] == True]\n",
    "D_run4_correct = D_run4_filtered[D_run4_filtered['outcome'] == True]\n",
    "\n",
    "# keep this dataframe and make normalized dataframe for within-subject errors \n",
    "D_run3_normalized = D_run3_correct.copy(deep = True)\n",
    "D_run4_normalized = D_run4_correct.copy(deep = True)\n",
    "\n",
    "reload(h)\n",
    "D_run3_normalized = h.grand_mean_normalize(D_run3_normalized, 'numStrokes', run3_complete_games)\n",
    "D_run3_normalized = h.grand_mean_normalize(D_run3_normalized, 'drawDuration', run3_complete_games)\n",
    "D_run3_normalized = h.grand_mean_normalize(D_run3_normalized, 'numCurvesPerSketch', run3_complete_games)\n",
    "D_run3_normalized = h.grand_mean_normalize(D_run3_normalized, 'meanPixelIntensity', run3_complete_games)\n",
    "\n",
    "D_run4_normalized = h.grand_mean_normalize(D_run4_normalized, 'numStrokes', run4_complete_games)\n",
    "D_run4_normalized = h.grand_mean_normalize(D_run4_normalized, 'drawDuration', run4_complete_games)\n",
    "D_run4_normalized = h.grand_mean_normalize(D_run4_normalized, 'numCurvesPerSketch', run4_complete_games)\n",
    "D_run4_normalized = h.grand_mean_normalize(D_run4_normalized, 'meanPixelIntensity', run4_complete_games)\n",
    "\n",
    "# writing out data \n",
    "\n",
    "## raw, unfiltered\n",
    "D_run3.to_csv(os.path.join(results_dir, 'graphical_conventions_{}_{}.csv'.format('run3', 'raw')))\n",
    "D_run4.to_csv(os.path.join(results_dir, 'graphical_conventions_{}_{}.csv'.format('run4', 'raw')))\n",
    "\n",
    "## filtered, but includes correct and incorrect trials \n",
    "D_run3_filtered.to_csv(os.path.join(results_dir, 'graphical_conventions_{}_{}.csv'.format('run3', 'filtered')))\n",
    "D_run4_filtered.to_csv(os.path.join(results_dir, 'graphical_conventions_{}_{}.csv'.format('run4', 'filtered')))\n",
    "\n",
    "## filtered, and correct trials only \n",
    "D_run3_correct.to_csv(os.path.join(results_dir,'graphical_conventions_{}_{}.csv'.format('run3', 'unnormalized')))\n",
    "D_run4_correct.to_csv(os.path.join(results_dir,'graphical_conventions_{}_{}.csv'.format('run4', 'unnormalized')))\n",
    "\n",
    "## filtered, correct trials only, and normalized within subject \n",
    "D_run3_normalized.to_csv(os.path.join(results_dir,'graphical_conventions_{}_{}.csv'.format('run3', 'normalized')))\n",
    "D_run4_normalized.to_csv(os.path.join(results_dir,'graphical_conventions_{}_{}.csv'.format('run4', 'normalized')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load in pre-existing dataframes to get png renders to extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpath = os.path.join(results_dir,'graphical_conventions_{}_{}.csv'.format('run3', 'unnormalized'))\n",
    "D_run3_correct = pd.read_csv(fpath)\n",
    "\n",
    "fpath = os.path.join(results_dir,'graphical_conventions_{}_{}.csv'.format('run4', 'unnormalized'))\n",
    "D_run4_correct = pd.read_csv(fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### actually render out pngs now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(h)\n",
    "h.save_sketches(D_run3_correct, sketch_dir, 'combined', 'run3')\n",
    "h.save_sketches(D_run4_correct, sketch_dir, 'combined', 'run4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
