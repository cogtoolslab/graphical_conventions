{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division\n",
    "\n",
    "import os\n",
    "import urllib, cStringIO\n",
    "\n",
    "import pymongo as pm\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "from PIL import Image\n",
    "import base64\n",
    "import sys\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "plt = pyplot\n",
    "import seaborn as sns\n",
    "sns.set_context('talk')\n",
    "sns.set_style('white')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# directory & file hierarchy\n",
    "proj_dir = os.path.abspath('../../..')\n",
    "analysis_dir = os.getcwd()\n",
    "results_dir = os.path.join(proj_dir,'results')\n",
    "plot_dir = os.path.join(results_dir,'plots')\n",
    "csv_dir = os.path.join(results_dir,'csv')\n",
    "exp_dir = os.path.abspath(os.path.join(proj_dir,'experiments'))\n",
    "sketch_dir = os.path.abspath(os.path.join(proj_dir,'sketches'))\n",
    "\n",
    "## add helpers to python path\n",
    "if os.path.join(proj_dir,'analysis','python') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir,'analysis','python'))\n",
    "    \n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "    \n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)   \n",
    "    \n",
    "if not os.path.exists(csv_dir):\n",
    "    os.makedirs(csv_dir)       \n",
    "    \n",
    "# Assign variables within imported analysis helpers\n",
    "import analysis_helpers as h\n",
    "if sys.version_info[0]>=3:\n",
    "    from importlib import reload\n",
    "reload(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set vars \n",
    "auth = pd.read_csv('auth.txt', header = None) # this auth.txt file contains the password for the sketchloop user\n",
    "pswd = auth.values[0][0]\n",
    "user = 'sketchloop'\n",
    "host = 'rxdhawkins.me' ## cocolab ip address\n",
    "\n",
    "# have to fix this to be able to analyze from local\n",
    "import pymongo as pm\n",
    "conn = pm.MongoClient('mongodb://sketchloop:' + pswd + '@127.0.0.1')\n",
    "db = conn['3dObjects']\n",
    "coll = db['graphical_conventions_recog']\n",
    "\n",
    "# which iteration name should we use?\n",
    "iterationName = 'pilot1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get basic participation stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## list of researchers\n",
    "researchers = ['A4SSYO0HDVD4E', 'A1BOIDKD33QSDK']\n",
    "num_correct_thresh = 0\n",
    "\n",
    "## get list of valid sessions with reasonable accuracy\n",
    "workers = coll.find({ '$and': [{'iterationName':iterationName}]}).distinct('workerId')\n",
    "workers = [i for i in workers if len(i)>10 and i not in researchers] ## filter workers\n",
    "print '{} workers performed this task'.format(len(workers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## get total number of recog events in the collection as a whole\n",
    "top_workers = []\n",
    "for i,w in enumerate(workers):\n",
    "    print 'Analyzing {} | {} of {}'.format(w,str(i).zfill(3),len(workers))\n",
    "    clear_output(wait=True)\n",
    "    R = coll.find({ '$and': [{'iterationName':iterationName}, {'workerId': w}]}).sort('time',-1)\n",
    "    num_correct = np.sum([r['correct'] for r in R])\n",
    "    if num_correct >= num_correct_thresh:\n",
    "        top_workers.append(w)\n",
    "        \n",
    "print '{} workers got at least {} correct.'.format(len(top_workers),num_correct_thresh)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### construct group dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## get total number of recog events in the collection as a whole\n",
    "# grab rep & accuracy\n",
    "from IPython.display import clear_output\n",
    "rep = []\n",
    "correct = []\n",
    "rt = []\n",
    "condition = []\n",
    "orig_correct = []\n",
    "generalization = []\n",
    "target = []\n",
    "distractor1 = []\n",
    "distractor2 = []\n",
    "distractor3 = []\n",
    "for i,w in enumerate(top_workers):\n",
    "    print 'Now analyzing {} | {} of {}'.format(w,str(i+1).zfill(3), len(top_workers))\n",
    "    clear_output(wait=True)\n",
    "    R = coll.find({ '$and': [{'iterationName':iterationName}, {'workerId': w}]}).sort('time')\n",
    "    for r in R:\n",
    "        rep.append(r['repetition'])\n",
    "        correct.append(r['correct'])\n",
    "        rt.append(r['rt'])\n",
    "        condition.append(r['condition'])\n",
    "        if 'outcome' in r.keys():\n",
    "            orig_correct.append(r['outcome'])\n",
    "        else:\n",
    "            orig_correct.append(r['original_correct'])\n",
    "        generalization.append(r['Generalization'])\n",
    "        target.append(r['target'])\n",
    "        distractor1.append(r['distractor1'])\n",
    "        distractor2.append(r['distractor2'])\n",
    "        distractor3.append(r['distractor3'])\n",
    "    \n",
    "## make dataframe\n",
    "X = pd.DataFrame([rep,correct,rt,condition,orig_correct,\\\n",
    "                 generalization,target,distractor1,distractor2,\\\n",
    "                 distractor3])\n",
    "X = X.transpose()\n",
    "X.columns = ['repetition','correct','rt','condition', 'orig_correct',\\\n",
    "             'generalization','target','distractor1','distractor2',\\\n",
    "             'distractor3']\n",
    "\n",
    "## convert datatypes to numeric\n",
    "X['correct'] = pd.to_numeric(X['correct'])\n",
    "X['rt'] = pd.to_numeric(X['rt'])\n",
    "X['orig_correct'] = pd.to_numeric(X['orig_correct'])\n",
    "    \n",
    "print 'Finished analyzing top workers.'\n",
    "print 'There are {} observation in the dataframe.'.format(X.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### preprocessing helper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## function to unroll target, distractor dicts into separate columns\n",
    "def dict2cols(X,item='target'):\n",
    "    '''\n",
    "    X = dataframe containing group data\n",
    "    item = which item column to unroll: target? distractor1? \n",
    "    '''\n",
    "    df = pd.DataFrame.from_dict(X[item]) ## make temporary dataframe with dictionary as main column\n",
    "    df2 = df[item].apply(pd.Series) ## separate into different columns\n",
    "    ## rename to ensure uniqueness\n",
    "    df3 = df2.rename(columns={'objectname': '{}_objectname'.format(item),\\\n",
    "                              'shapenetid': '{}_shapenetid'.format(item),\\\n",
    "                              'url': '{}_url'.format(item)})\n",
    "    X2 = X.join(df3) ## add to original group dataframe\n",
    "    X2.drop(labels=[item],axis=1,inplace=True) ## remove old dictionary column\n",
    "    return X2\n",
    "\n",
    "## now actually apply unrolling function\n",
    "items = ['target','distractor1','distractor2','distractor3']\n",
    "for item in items: \n",
    "    print 'Unrolling {}'.format(item)\n",
    "    clear_output(wait=True)\n",
    "    if item in X.columns:\n",
    "        X = dict2cols(X,item=item)\n",
    "        \n",
    "print 'Finished unrolling item dictionaries into separate columns.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.groupby(['condition','repetition'])['correct'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize recognizability x repetition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## get dataframe subsetted by condition and broken out by target\n",
    "X2 = X.query(\"condition=='repeated'\")\n",
    "X2 = X2.sort_values(by=['target_objectname'])\n",
    "targ_list = np.unique(X2.target_objectname.values)\n",
    "sns.set_context('talk')\n",
    "\n",
    "## plot recognizxability, collapsing across target\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "sns.lineplot(data=X2,x='repetition',y='correct')\n",
    "plt.ylim(0,1)\n",
    "plt.yticks(np.arange(0, 1, 0.1))\n",
    "plt.xticks(np.arange(0, 8, 1))\n",
    "plt.plot([0,7],[0.25,0.25],color='black',linestyle=':')\n",
    "\n",
    "## plot recognizability, split out by target\n",
    "fig = plt.figure(figsize=(16,16))\n",
    "g = sns.FacetGrid(X2, col=\"target_objectname\", col_wrap=4,height=3, margin_titles=False)\n",
    "g.map(sns.lineplot, \"repetition\", \"correct\", alpha=.7)\n",
    "g.set_titles(\"{col_name}\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize rt x repetition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## get dataframe subsetted by condition and broken out by target\n",
    "X2 = X.query(\"condition=='repeated'\")\n",
    "X2 = X2.sort_values(by=['target_objectname'])\n",
    "targ_list = np.unique(X2.target_objectname.values)\n",
    "sns.set_context('talk')\n",
    "\n",
    "## plot recognizxability, collapsing across target\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "sns.lineplot(data=X2,x='repetition',y='rt')\n",
    "plt.ylim(0,1)\n",
    "plt.yticks(np.arange(0, 10000, 2000))\n",
    "plt.xticks(np.arange(0, 8, 1))\n",
    "\n",
    "## plot recognizability, split out by target\n",
    "fig = plt.figure(figsize=(16,16))\n",
    "g = sns.FacetGrid(X2, col=\"target_objectname\", col_wrap=4,height=3, margin_titles=False)\n",
    "g.map(sns.lineplot, \"repetition\", \"rt\", alpha=.7)\n",
    "g.set_titles(\"{col_name}\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for use while running experiment to check on final scores of individual participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## get final score for particular worker\n",
    "w = top_workers[0]\n",
    "coll.find_one({ '$and': [{'iterationName':iterationName}, \\\n",
    "                        {'workerId': w}]}, \\\n",
    "                        sort=[(\"score\", -1)])[\"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
