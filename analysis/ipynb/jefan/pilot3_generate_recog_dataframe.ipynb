{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division\n",
    "\n",
    "import os\n",
    "import urllib, cStringIO\n",
    "\n",
    "import pymongo as pm\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "from PIL import Image\n",
    "import base64\n",
    "import sys\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "plt = pyplot\n",
    "import seaborn as sns\n",
    "sns.set_context('talk')\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# directory & file hierarchy\n",
    "proj_dir = os.path.abspath('../../..')\n",
    "analysis_dir = os.getcwd()\n",
    "results_dir = os.path.join(proj_dir,'results')\n",
    "stimuli_dir = os.path.join(proj_dir,'stimuli')\n",
    "plot_dir = os.path.join(results_dir,'plots')\n",
    "csv_dir = os.path.join(results_dir,'csv')\n",
    "exp_dir = os.path.abspath(os.path.join(proj_dir,'experiments'))\n",
    "sketch_dir = os.path.abspath(os.path.join(proj_dir,'sketches'))\n",
    "\n",
    "## add helpers to python path\n",
    "if os.path.join(proj_dir,'analysis','python') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir,'analysis','python'))\n",
    "    \n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "    \n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)   \n",
    "    \n",
    "if not os.path.exists(csv_dir):\n",
    "    os.makedirs(csv_dir)       \n",
    "    \n",
    "# Assign variables within imported analysis helpers\n",
    "import analysis_helpers as h\n",
    "if sys.version_info[0]>=3:\n",
    "    from importlib import reload\n",
    "reload(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set vars \n",
    "auth = pd.read_csv('auth.txt', header = None) # this auth.txt file contains the password for the sketchloop user\n",
    "pswd = auth.values[0][0]\n",
    "user = 'sketchloop'\n",
    "host = 'rxdhawkins.me' ## cocolab ip address\n",
    "\n",
    "# have to fix this to be able to analyze from local\n",
    "import pymongo as pm\n",
    "conn = pm.MongoClient('mongodb://sketchloop:' + pswd + '@127.0.0.1')\n",
    "db = conn['3dObjects']\n",
    "coll = db['graphical_conventions_recog']\n",
    "\n",
    "# which iteration name should we use?\n",
    "iterationName = 'pilot3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get basic participation stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## list of researchers\n",
    "researchers = ['A4SSYO0HDVD4E', 'A1BOIDKD33QSDK','A1MMCS8S8CTWKU']\n",
    "num_correct_thresh = 0\n",
    "num_catch_correct_thresh = 4\n",
    "\n",
    "## get list of valid sessions with reasonable accuracy\n",
    "workers = coll.find({ '$and': [{'iterationName':iterationName}]}).distinct('workerId')\n",
    "workers = [i for i in workers if len(i)>10 and i not in researchers] ## filter workers\n",
    "print '{} workers performed this task'.format(len(workers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## get total number of recog events in the collection as a whole\n",
    "top_workers = []\n",
    "catch_passable = []\n",
    "for i,w in enumerate(workers):\n",
    "    print 'Analyzing {} | {} of {}'.format(w,str(i).zfill(3),len(workers))\n",
    "    clear_output(wait=True)\n",
    "    R = coll.find({ '$and': [{'iterationName':iterationName}, {'workerId': w}]}).sort('time',-1)\n",
    "    if R.count()==45:\n",
    "        num_correct = coll.find({ '$and': [{'iterationName':iterationName}, {'workerId': w},{'catch_trial':False},{'correct':1}]}).sort('time',-1).count()\n",
    "        num_catch_trial_correct = coll.find({ '$and': [{'iterationName':iterationName}, {'workerId': w},{'catch_trial':True},{'correct':1}]}).sort('time',-1).count()    \n",
    "        num_catch_trials_shown = coll.find({ '$and': [{'iterationName':iterationName}, {'workerId': w},{'catch_trial':True}]}).sort('time',-1).count()\n",
    "        catch_passable.append(num_catch_trial_correct)\n",
    "        ## make sure: (1) num correct was higher than thresh, (2) all 5 catch trials showed, \n",
    "        ## (3) catch trials were correct above threshold, and (4) it was a full session \n",
    "        if (num_correct >= num_correct_thresh) & (num_catch_trials_shown==5) & \\\n",
    "            (num_catch_trial_correct >= num_catch_correct_thresh): \n",
    "                top_workers.append(w)\n",
    "        \n",
    "print '{} workers got at least {} experimental trials correct and {} catch trials correct and finished the entire HIT.'.format(len(top_workers),num_correct_thresh, num_catch_correct_thresh)        \n",
    "print '{} workers out of {} got fewer than the threshold correct.'format(np.sum(np.array(catch_passable)<num_catch_correct_thresh), len(catch_passable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ## check how much to bonus a particular worker via compensation HIT\n",
    "# reallyRun = False\n",
    "# if reallyRun:\n",
    "#     w = ''\n",
    "#     C = coll.find({ '$and': [{'iterationName':iterationName}, {'workerId': w}]}).sort('time',-1)\n",
    "#     for c in C:\n",
    "#         print c['score'], c['numCorrectSoFar']\n",
    "#         clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### construct group dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## get total number of recog events in the collection as a whole\n",
    "# grab rep & accuracy\n",
    "rep = []\n",
    "correct = []\n",
    "rt = []\n",
    "condition = []\n",
    "orig_correct = []\n",
    "generalization = []\n",
    "target = []\n",
    "distractor1 = []\n",
    "distractor2 = []\n",
    "distractor3 = []\n",
    "orig_gameID = []\n",
    "gameID = []\n",
    "version = [] ## yoked vs. scrambled40 vs. scrambled 10\n",
    "recog_id = []\n",
    "for i,w in enumerate(top_workers):\n",
    "    print 'Now analyzing {} | {} of {}'.format(w,str(i+1).zfill(3), len(top_workers))\n",
    "    clear_output(wait=True)\n",
    "    R = coll.find({ '$and': [{'iterationName':iterationName}, {'workerId': w},{'catch_trial':False}]}).sort('time')\n",
    "    for r in R:        \n",
    "        rep.append(r['repetition'])\n",
    "        correct.append(r['correct'])\n",
    "        rt.append(r['rt'])\n",
    "        condition.append(r['condition'])\n",
    "        if 'outcome' in r.keys():\n",
    "            orig_correct.append(r['outcome'])\n",
    "        else:\n",
    "            orig_correct.append(r['original_correct'])\n",
    "        generalization.append(r['Generalization'])\n",
    "        target.append(r['target'])\n",
    "        distractor1.append(r['distractor1'])\n",
    "        distractor2.append(r['distractor2'])\n",
    "        distractor3.append(r['distractor3'])\n",
    "        orig_gameID.append(r['sketch'].split('_')[0])\n",
    "        gameID.append(r['gameID'])\n",
    "        version.append(r['version'])\n",
    "        recog_id.append(r['recog_id'])\n",
    "    \n",
    "### make dataframe\n",
    "X = pd.DataFrame([rep,correct,rt,condition,orig_correct,\\\n",
    "                 generalization,target,distractor1,distractor2,\\\n",
    "                 distractor3,orig_gameID,gameID,version,recog_id])\n",
    "X = X.transpose()\n",
    "X.columns = ['repetition','correct','rt','condition', 'orig_correct',\\\n",
    "             'generalization','target','distractor1','distractor2',\\\n",
    "             'distractor3','orig_gameID','gameID','version','recog_id']\n",
    "\n",
    "## convert datatypes to numeric\n",
    "X['correct'] = pd.to_numeric(X['correct'])\n",
    "X['rt'] = pd.to_numeric(X['rt'])\n",
    "X['orig_correct'] = pd.to_numeric(X['orig_correct'])\n",
    "    \n",
    "print 'Finished analyzing top workers.'\n",
    "print 'There are {} observation in the dataframe.'.format(X.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### preprocessing helper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## function to unroll target, distractor dicts into separate columns\n",
    "def dict2cols(X,item='target'):\n",
    "    '''\n",
    "    X = dataframe containing group data\n",
    "    item = which item column to unroll: target? distractor1? \n",
    "    '''\n",
    "    df = pd.DataFrame.from_dict(X[item]) ## make temporary dataframe with dictionary as main column\n",
    "    df2 = df[item].apply(pd.Series) ## separate into different columns\n",
    "    ## rename to ensure uniqueness\n",
    "    df3 = df2.rename(columns={'objectname': '{}_objectname'.format(item),\\\n",
    "                              'shapenetid': '{}_shapenetid'.format(item),\\\n",
    "                              'url': '{}_url'.format(item)})\n",
    "    X2 = X.join(df3) ## add to original group dataframe\n",
    "    X2.drop(labels=[item],axis=1,inplace=True) ## remove old dictionary column\n",
    "    return X2\n",
    "\n",
    "## now actually apply unrolling function\n",
    "items = ['target','distractor1','distractor2','distractor3']\n",
    "for item in items: \n",
    "    print 'Unrolling {}'.format(item)\n",
    "    clear_output(wait=True)\n",
    "    if item in X.columns:\n",
    "        X = dict2cols(X,item=item)\n",
    "        \n",
    "print 'Finished unrolling item dictionaries into separate columns.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## view recognizability by repetition in tabular form\n",
    "X.groupby(['condition','repetition'])['correct'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## how many games from each version were finished?\n",
    "X.groupby('version')['repetition'].count()/40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check representation of original game data in yoked/scrambled40 experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## subset by yoked experiment \n",
    "Y = X[X['version']=='yoked']\n",
    "\n",
    "## which orig_gameIDs got played in yoked?\n",
    "orig_gameIDs_yoked = Counter(Y['orig_gameID']).keys()\n",
    "\n",
    "## how many orig_gameIDs got played in yoked?\n",
    "num_unique_orig_games = len(Counter(Y['orig_gameID']).keys())\n",
    "print '{} original gameIDs appeared in the yoked experiment.'.format(num_unique_orig_games)\n",
    "\n",
    "## how many times did each of the orig_gameIDs that did appear in yoked experiment get played?\n",
    "orig_gameIDs_reps = Counter([int(i/40) for i in Counter(Y['orig_gameID']).values()])\n",
    "for entry in orig_gameIDs_reps.keys():\n",
    "    print '   {} were played {} times in the yoked experiment.'.format(orig_gameIDs_reps[entry],entry)\n",
    "\n",
    "## which original gameIDs not yet represented in the yoked dataset?\n",
    "## load in original group_data\n",
    "path_to_group_data = os.path.join(results_dir,'graphical_conventions.csv')\n",
    "O = pd.read_csv(path_to_group_data)\n",
    "orig_gameID_list = list(np.unique(O['gameID']))\n",
    "orig_gameIDs_not_yet_yoked = [i for i in orig_gameID_list if i not in orig_gameIDs_yoked]\n",
    "print 'There are {} original gameIDs that have not yet been played in the yoked experiment.'.format(len(orig_gameIDs_not_yet_yoked))\n",
    "\n",
    "## save out list of gameIDs remaining in the stimuli folder, to allow these to be uploaded as their own dataset\n",
    "## for targeted recruitment\n",
    "if len(orig_gameIDs_not_yet_yoked)>=1:\n",
    "    U = pd.DataFrame(orig_gameIDs_not_yet_yoked)\n",
    "    U.columns = ['gameID']\n",
    "    U.to_csv(os.path.join(stimuli_dir,'orig_gameIDs_remaining_yoked.csv'),index=False)\n",
    "    print 'Saving out this list of gameIDs in the stimuli folder, to allow these to be uploaded as their own dataset for targeted recruitment.'\n",
    "else:\n",
    "    print 'All original gameIDs have appeared in the yoked experiment.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## subset by scrambled40\n",
    "S = X[X['version']=='scrambled40']\n",
    "\n",
    "## how many recog_ids got played in yoked?\n",
    "num_unique_orig_recogids = len(Counter(S['recog_id']).keys())\n",
    "print '{} recog_ids appeared in the scrambled40 experiment.'.format(num_unique_orig_recogids)\n",
    "\n",
    "## which recog_ids got played in scrambled40?\n",
    "recog_ids_scrambled = Counter(S['recog_id']).keys()\n",
    "\n",
    "recog_id_reps = Counter([int(i) for i in Counter(S['recog_id']).values()])\n",
    "for entry in sorted(recog_id_reps.keys()):\n",
    "    print '   {} games appeared {} trials from them appear in the scrambled40 experiment.'.format(recog_id_reps[entry],entry)\n",
    "\n",
    "## which recog_ids remaining?\n",
    "recog_id_list = list(np.unique(O['recog_id']))\n",
    "recog_ids_remaining = [i for i in recog_id_list if i not in recog_ids_scrambled]\n",
    "grouped_recog_ids_remaining = np.unique([np.int64(i/4) for i in recog_ids_remaining])\n",
    "print 'There are still {} grouped_recog_ids to run.'.format(len(grouped_recog_ids_remaining))\n",
    "\n",
    "if len(grouped_recog_ids_remaining)>=1:\n",
    "    U = pd.DataFrame(grouped_recog_ids_remaining)\n",
    "    U.columns = ['grouped_recog_id']\n",
    "    U.to_csv(os.path.join(stimuli_dir,'grouped_recog_ids_remaining_scrambled40.csv'),index=False)\n",
    "    print 'Saving out this list of recogIDs in the stimuli folder, to allow these to be uploaded as their own dataset for targeted recruitment.'\n",
    "else:\n",
    "    print 'All original grouped_recog_ids have appeared in the yoked experiment.'    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize recognizability x repetition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## get dataframe subsetted by condition and broken out by target\n",
    "X2 = X[X['condition']=='repeated'].reset_index(drop=True)\n",
    "X2 = X2.sort_values(by=['target_objectname'])\n",
    "targ_list = np.unique(X2.target_objectname.values)\n",
    "sns.set_context('talk')\n",
    "\n",
    "## plot recognizability, collapsing across target\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "sns.lineplot(data=X2,x='repetition',y='correct',hue='version')\n",
    "plt.ylim(0,1)\n",
    "plt.yticks(np.arange(0, 1, 0.1))\n",
    "plt.xticks(np.arange(0, 8, 1))\n",
    "plt.plot([0,7],[0.25,0.25],color='black',linestyle=':')\n",
    "plt.legend(loc = 'lower right')\n",
    "\n",
    "# ## plot recognizability, split out by target\n",
    "# fig = plt.figure(figsize=(16,16))\n",
    "# g = sns.FacetGrid(X2, col=\"target_objectname\", col_wrap=4,height=3, margin_titles=False)\n",
    "# g.map(sns.lineplot, \"repetition\", \"correct\", alpha=.7)\n",
    "# g.set_titles(\"{col_name}\")\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### aggregate with original refgame dataset and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## load in original group_data\n",
    "path_to_group_data = os.path.join(results_dir,'graphical_conventions.csv')\n",
    "O = pd.read_csv(path_to_group_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## aggregate original refgame and recog dataframes\n",
    "## and add some handy additional fields\n",
    "OR = O[O['condition']=='repeated'].reset_index(drop=True)\n",
    "OR = OR.rename(columns={'outcome':'correct'})\n",
    "OR['logRT'] = np.log(OR['drawDuration']*1000)\n",
    "OR['version'] = pd.Series(['refgame']*len(OR))\n",
    "X2['logRT'] = np.log(X2['rt']) ## add log RT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## save out concatenated dataframe for stats\n",
    "_OR = OR[['version','repetition','gameID','condition','target', 'correct', 'logRT']]\n",
    "_X2 = X2[['version','repetition','gameID','condition','target_objectname','correct', 'logRT']]\n",
    "_X2.rename({'target_objectname':'target'}, axis='columns',inplace=True)\n",
    "## concatenated original and recog experiments\n",
    "R = pd.concat([_OR,_X2],axis=0,sort=False).reset_index()\n",
    "R.to_csv(os.path.join(results_dir,'graphical_conventions_recog_data.csv'),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## plot accuracy timecourse\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "sns.lineplot(data=R,x='repetition',y='correct',hue='version')\n",
    "plt.ylim(0,1)\n",
    "plt.yticks(np.arange(0, 1, 0.1))\n",
    "plt.xticks(np.arange(0, 8, 1))\n",
    "plt.plot([0,7],[0.25,0.25],color='black',linestyle=':')\n",
    "plt.legend(loc = 'lower right')\n",
    "t = plt.title('Comparing recognizability in refgame vs. recog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4,4))\n",
    "sns.lineplot(data=R,x='repetition',y='logRT',hue='version')\n",
    "plt.ylim(0,10)\n",
    "plt.yticks(np.arange(0, 10, 1))\n",
    "plt.xticks(np.arange(0, 8, 1))\n",
    "# plt.plot([0,7],[0.25,0.25],color='black',linestyle=':')\n",
    "plt.legend(loc = 'lower right')\n",
    "t = plt.title('Comparing RT in refgame vs. recog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute BIS (z-score within original gameID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zscore(x,mu,sd):\n",
    "    return (x-mu)/(sd+1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## sort dataframe by original gameID, repetition, and target_objectname\n",
    "X3 = X2.sort_values(by=['orig_gameID','repetition','target_objectname']).reset_index(drop=True)\n",
    "\n",
    "## subset by yoked experiment data only\n",
    "X3 = X3[X3['version']=='yoked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## groupby original gameID\n",
    "grouped = X3.groupby('orig_gameID')\n",
    "\n",
    "## init new aggregated vars\n",
    "acc_norm = []\n",
    "rt_norm = []\n",
    "bis = []\n",
    "orig_gameID = []\n",
    "repetition = []\n",
    "version = []\n",
    "\n",
    "## loop through games\n",
    "for name, group in grouped:\n",
    "    print 'Analyzing {}'.format(name)\n",
    "    clear_output(wait=True)\n",
    "    rt_mu = group['logRT'].mean()\n",
    "    rt_sd = group['logRT'].std()    \n",
    "    acc_mu = group['correct'].mean()\n",
    "    acc_sd = group['correct'].std()\n",
    "    repwise = group.groupby('repetition')\n",
    "    ## loop through reps within games\n",
    "    for name,rep in repwise:\n",
    "        rep_acc_raw = rep['correct'].mean()\n",
    "        rep_rt_raw = rep['logRT'].mean()  \n",
    "        accN = zscore(rep_acc_raw,acc_mu,acc_sd)\n",
    "        rtN = zscore(rep_rt_raw,rt_mu,rt_sd)\n",
    "        acc_norm.append(accN)\n",
    "        rt_norm.append(rtN)\n",
    "        bis.append(accN-rtN)\n",
    "        assert len(np.unique(rep['orig_gameID'].values))==1\n",
    "        orig_gameID.append(np.unique(rep['orig_gameID'].values)[0])\n",
    "        repetition.append(np.unique(rep['repetition'].values)[0])\n",
    "        version.append(np.unique(group['version'])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## construct dataframe\n",
    "X4 = pd.DataFrame([orig_gameID,repetition,acc_norm,rt_norm,bis,version])\n",
    "X4 = X4.transpose()\n",
    "X4.columns = ['orig_gameID','repetition','acc_norm','rt_norm','bis','version']\n",
    "\n",
    "## convert to numeric datatype\n",
    "X4['bis']=pd.to_numeric(pd.Series(X4['bis']))\n",
    "X4['acc_norm']=pd.to_numeric(pd.Series(X4['acc_norm']))\n",
    "X4['rt_norm']=pd.to_numeric(pd.Series(X4['rt_norm']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## visualize BIS x repetition\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "sns.lineplot(data=X4,x='repetition',y='bis',hue='version')\n",
    "plt.ylim(-1,1)\n",
    "t = plt.yticks(np.arange(-1, 1.1, 0.5))\n",
    "t = plt.xticks(np.arange(0, 8, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for use while running experiment to check on final scores of individual participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## get final score for particular worker\n",
    "w = top_workers[0]\n",
    "coll.find_one({ '$and': [{'iterationName':iterationName}, \\\n",
    "                        {'workerId': w}]}, \\\n",
    "                        sort=[(\"score\", -1)])[\"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract especially recognizable sketches from most accurate game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rationale for this is to extract sketches of targets in context from a particularly well recognized game that we can use as ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## compute overall accuracy in context of original refgame and in recog experiment\n",
    "OG = pd.DataFrame(X3.groupby('orig_gameID')['orig_correct'].mean())\n",
    "NG = pd.DataFrame(X3.groupby('orig_gameID')['correct'].mean())\n",
    "\n",
    "## get top games according to both forms of accuracy\n",
    "old_top_games = OG.sort_values(by='orig_correct',ascending=False).reset_index().iloc[0:8]['orig_gameID'].values\n",
    "new_top_games = NG.sort_values(by='correct',ascending=False).reset_index().iloc[0:4]['orig_gameID'].values\n",
    "## id for game that had both high accuracy in original game and relatively high recog accuracy\n",
    "best_game = [i for i in new_top_games if i in old_top_games]\n",
    "best_game = best_game[0]\n",
    "print 'Best game ID is {}.'.format(best_game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recog_correct_trials_from_best = X3[(X3['orig_gameID']==best_game) & (X3['correct']==True)].reset_index(drop=True)\n",
    "C = recog_correct_trials_from_best\n",
    "correct_rep_obj_combos = zip(C['repetition'].values,C['target_objectname'].values)\n",
    "print 'Correct recog trials from best game: {}'.format(len(correct_rep_obj_combos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_group_data = os.path.join(results_dir,'graphical_conventions.csv')\n",
    "O = pd.read_csv(path_to_group_data)\n",
    "\n",
    "## remove unnecessary columns\n",
    "if 'Unnamed: 0' in O.columns:\n",
    "    O = O.drop(labels=['Unnamed: 0','row_index'], axis=1)\n",
    "    \n",
    "## subset columns that are going to be in the stimuli database for the recognition experiment\n",
    "## basically, retain everything except for bigger pieces of data, e.g., png and svgString\n",
    "O2 = O.drop(labels=['png','svgString'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## subset to just best game's sketches\n",
    "O2_best = O2[O2['gameID']==best_game].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## assign new column that keeps track of whether this sketch was correctly recognized in pilot\n",
    "recog_pilot_correct = []\n",
    "for i,d in O2_best.iterrows():\n",
    "    recog_pilot_correct.append(tuple((d['repetition'],d['target'])) in correct_rep_obj_combos)\n",
    "O2_best['recog_pilot_correct'] = recog_pilot_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## subset by this sketch being correctly recognized in the recog pilot experiment\n",
    "O2_best_correct = O2_best[O2_best['recog_pilot_correct']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "stimdict = O2_best_correct.to_dict(orient=\"records\")\n",
    "for trial in stimdict:\n",
    "    target_shapenet = trial['target_shapenet']\n",
    "    distractors_shapenet = ast.literal_eval(trial['distractors_shapenet'])\n",
    "    distractors = ast.literal_eval(trial['distractors'])\n",
    "    trial['target'] = {'shapenetid':target_shapenet, 'objectname': trial['target'], 'url': 'https://s3.amazonaws.com/shapenet-graphical-conventions/' + target_shapenet+'.png'}\n",
    "    trial['distractor1'] = {'shapenetid':distractors_shapenet['distractor1'], 'objectname': distractors['distractor1'], 'url': 'https://s3.amazonaws.com/shapenet-graphical-conventions/' + distractors_shapenet['distractor1'] + '.png'}\n",
    "    trial['distractor2'] = {'shapenetid':distractors_shapenet['distractor2'], 'objectname': distractors['distractor2'], 'url': 'https://s3.amazonaws.com/shapenet-graphical-conventions/' + distractors_shapenet['distractor2'] + '.png'}\n",
    "    trial['distractor3'] = {'shapenetid':distractors_shapenet['distractor3'], 'objectname': distractors['distractor3'], 'url': 'https://s3.amazonaws.com/shapenet-graphical-conventions/' + distractors_shapenet['distractor3'] + '.png'}\n",
    "    trial['sketch'] = str(trial['gameID']) + '_' + str( trial['repetition']).zfill(2) + '_' + str(trial['target']['objectname'])\n",
    "    trial['sketch_url'] = 'https://s3.amazonaws.com/graphical-conventions-sketches/' + trial['sketch'] + '.png'\n",
    "print 'All done constructing meta for best game.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib, cStringIO\n",
    "from IPython.display import display\n",
    "\n",
    "this_trial = 5 ## this one of folding chair seems pretty obvious\n",
    "\n",
    "this_sketch_url = stimdict[this_trial]['sketch_url']\n",
    "f = cStringIO.StringIO(urllib.urlopen(this_sketch_url).read())\n",
    "x = Image.open(f)\n",
    "\n",
    "this_url = stimdict[this_trial]['target']['url']\n",
    "f = cStringIO.StringIO(urllib.urlopen(this_url).read())\n",
    "t = Image.open(f)\n",
    "\n",
    "this_url = stimdict[this_trial]['distractor1']['url']\n",
    "f = cStringIO.StringIO(urllib.urlopen(this_url).read())\n",
    "d1 = Image.open(f)\n",
    "\n",
    "this_url = stimdict[this_trial]['distractor2']['url']\n",
    "f = cStringIO.StringIO(urllib.urlopen(this_url).read())\n",
    "d2 = Image.open(f)\n",
    "\n",
    "this_url = stimdict[this_trial]['distractor3']['url']\n",
    "f = cStringIO.StringIO(urllib.urlopen(this_url).read())\n",
    "d3 = Image.open(f)\n",
    "\n",
    "display(x,t,d1,d2,d3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "catch_trial_imgs = stimdict[this_trial]\n",
    "\n",
    "## save out catch_trial_imgs in stimuli folder and in the experiments foler\n",
    "import json\n",
    "with open(os.path.join(proj_dir,'stimuli','catch_trial_imgs.js'), 'w') as fout:\n",
    "     json.dump(catch_trial_imgs, fout)\n",
    "        \n",
    "with open(os.path.join(exp_dir,'recog','catch_trial_imgs.js'), 'w') as fout:\n",
    "     json.dump(catch_trial_imgs, fout)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
