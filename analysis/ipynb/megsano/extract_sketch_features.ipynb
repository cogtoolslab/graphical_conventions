{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/megsano/.local/lib/python2.7/site-packages/cryptography/hazmat/primitives/constant_time.py:26: CryptographyDeprecationWarning: Support for your Python version is deprecated. The next version of cryptography will remove support. Please upgrade to a 2.7.x release that supports hmac.compare_digest as soon as possible.\n",
      "  utils.DeprecatedIn23,\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/special/__init__.py:640: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._ufuncs import *\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/linalg/basic.py:17: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._solve_toeplitz import levinson\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/linalg/__init__.py:191: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._decomp_update import *\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/special/_ellip_harm.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._ellip_harm_2 import _ellipsoid, _ellipsoid_norm\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/sparse/lil.py:16: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _csparsetools\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/sparse/csgraph/__init__.py:167: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._shortest_path import shortest_path, floyd_warshall, dijkstra,\\\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/sparse/csgraph/_validation.py:5: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._tools import csgraph_to_dense, csgraph_from_dense,\\\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/sparse/csgraph/__init__.py:169: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._traversal import breadth_first_order, depth_first_order, \\\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/sparse/csgraph/__init__.py:171: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._min_spanning_tree import minimum_spanning_tree\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/sparse/csgraph/__init__.py:172: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._reordering import reverse_cuthill_mckee, maximum_bipartite_matching, \\\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/optimize/_numdiff.py:8: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._group_columns import group_dense, group_sparse\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/interpolate/_bsplines.py:9: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _bspl\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/spatial/__init__.py:94: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .ckdtree import *\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/spatial/__init__.py:95: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .qhull import *\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/spatial/_spherical_voronoi.py:18: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _voronoi\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/spatial/distance.py:121: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _hausdorff\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/stats/_continuous_distns.py:17: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _stats\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/cluster/vq.py:88: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _vq\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/cluster/hierarchy.py:178: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _hierarchy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: argparse in /usr/lib/python2.7\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "# from torchvision.models.vgg import model_urls\n",
    "# model_urls['vgg16'] = model_urls['vgg16'].replace('https://', 'http://')\n",
    "#print torch.__version__\n",
    "\n",
    "vgg19 = models.vgg19(pretrained=True)\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "plt = pyplot\n",
    "import seaborn as sns\n",
    "sns.set_context('talk')\n",
    "sns.set_style('white')\n",
    "\n",
    "from PIL import Image\n",
    "import base64\n",
    "\n",
    "from embeddings import *\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "!pip install argparse\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve sketch paths\n",
    "def list_files(path, ext='png'):\n",
    "    result = [y for x in os.walk(path) for y in glob(os.path.join(x[0], '*.%s' % ext))]\n",
    "    return result\n",
    "\n",
    "def check_invalid_sketch(filenames,invalids_path='drawings_to_exclude.txt'):    \n",
    "    if not os.path.exists(invalids_path):\n",
    "        print('No file containing invalid paths at {}'.format(invalids_path))\n",
    "        invalids = []        \n",
    "    else:\n",
    "        x = pd.read_csv(invalids_path, header=None)\n",
    "        x.columns = ['filenames']\n",
    "        invalids = list(x.filenames.values)\n",
    "    valids = []   \n",
    "    basenames = [f.split('/')[-1] for f in filenames]\n",
    "    for i,f in enumerate(basenames):\n",
    "        if f not in invalids:\n",
    "            valids.append(filenames[i])\n",
    "    return valids\n",
    "\n",
    "def make_dataframe(Labels):    \n",
    "    Y = pd.DataFrame([Labels])\n",
    "    Y = Y.transpose()\n",
    "    Y.columns = ['label']\n",
    "    return Y\n",
    "\n",
    "def normalize(X):\n",
    "    X = X - X.mean(0)\n",
    "    X = X / np.maximum(X.std(0), 1e-5)\n",
    "    return X\n",
    "\n",
    "def preprocess_features(Features, Y):\n",
    "    _Y = Y.sort_values(['label'])\n",
    "    inds = np.array(_Y.index)\n",
    "    _Features = normalize(Features[inds])\n",
    "    _Y = _Y.reset_index(drop=True) # reset pandas dataframe index\n",
    "    return _Features, _Y\n",
    "\n",
    "def save_features(Features, Y, layer_num, data_type,feat_path='~/combined_sketch_features'):\n",
    "    if not os.path.exists('~/combined_sketch_features'):\n",
    "        os.makedirs('~/combined_sketch_features')\n",
    "    layers = ['P1','P2','P3','P4','P5','FC6','FC7']\n",
    "    np.save(os.path.join(feat_path,'FEATURES_{}_{}.npy'.format(layers[int(layer_num)], data_type)), Features)\n",
    "    Y.to_csv(os.path.join(feat_path,'METADATA_{}.csv'.format(data_type)))\n",
    "    return layers[int(layer_num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_Features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of image_paths before filtering: 1887\n",
      "No file containing invalid paths at drawings_to_exclude.txt\n",
      "Length of image_paths after filtering: 1887\n",
      "CUDA DEVICE NUM: 0\n",
      "Batch 1\n",
      "batch size: 64\n",
      "Batch 2\n",
      "batch size: 64\n",
      "Batch 3\n",
      "batch size: 64\n",
      "Batch 4\n",
      "batch size: 64\n",
      "Batch 5\n",
      "batch size: 64\n",
      "Batch 6\n",
      "batch size: 64\n",
      "Batch 7\n",
      "batch size: 64\n",
      "Batch 8\n",
      "batch size: 64\n",
      "Batch 9\n",
      "batch size: 64\n",
      "Batch 10\n",
      "batch size: 64\n",
      "Batch 11\n",
      "batch size: 64\n",
      "Batch 12\n",
      "batch size: 64\n",
      "Batch 13\n",
      "batch size: 64\n",
      "Batch 14\n",
      "batch size: 64\n",
      "Batch 15\n",
      "batch size: 64\n",
      "Batch 16\n",
      "batch size: 64\n",
      "Batch 17\n",
      "batch size: 64\n",
      "Batch 18\n",
      "batch size: 64\n",
      "Batch 19\n",
      "batch size: 64\n",
      "Batch 20\n",
      "batch size: 64\n",
      "Batch 21\n",
      "batch size: 64\n",
      "Batch 22\n",
      "batch size: 64\n",
      "Batch 23\n",
      "batch size: 64\n",
      "Batch 24\n",
      "batch size: 64\n",
      "Batch 25\n",
      "batch size: 64\n",
      "Batch 26\n",
      "batch size: 64\n",
      "Batch 27\n",
      "batch size: 64\n",
      "Batch 28\n",
      "batch size: 64\n",
      "Batch 29\n",
      "batch size: 64\n",
      "Batch 30\n",
      "batch size: 64\n",
      "stopped!\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data', type=str, help='full path to images', default='combined_final_png_drawings')\n",
    "parser.add_argument('--layer_ind', help='fc6 = 5, fc7 = 6', default=5)\n",
    "parser.add_argument('--data_type', help='\"images\" or \"sketch\"', default='sketch')\n",
    "parser.add_argument('--spatial_avg', type=bool, help='collapse over spatial dimensions, preserving channel activation only if true', default=False)     \n",
    "parser.add_argument('--test', type=bool, help='testing only, do not save features', default=False)  \n",
    "parser.add_argument('--ext', type=str, help='image extension type (e.g., \"png\")', default=\"png\")   \n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "# args = parser.parse_args(argv[1:])\n",
    "\n",
    "## get list of all sketch paths\n",
    "image_paths = sorted(list_files(args.data,args.ext))\n",
    "print('Length of image_paths before filtering: {}'.format(len(image_paths)))\n",
    "\n",
    "## filter out invalid sketches\n",
    "image_paths = check_invalid_sketch(image_paths)\n",
    "print('Length of image_paths after filtering: {}'.format(len(image_paths)))    \n",
    "\n",
    "## extract features\n",
    "layers = ['P1','P2','P3','P4','P5','FC6','FC7']\n",
    "extractor = FeatureExtractor(image_paths,layer=args.layer_ind,data_type=args.data_type,spatial_avg=args.spatial_avg)\n",
    "Features, Labels = extractor.extract_feature_matrix()   \n",
    "\n",
    "# organize metadata into dataframe\n",
    "Y = make_dataframe(Labels)\n",
    "_Features, _Y = preprocess_features(Features, Y)\n",
    "\n",
    "if args.test==False:\n",
    "    layer = save_features(_Features, _Y, args.layer_ind, args.data_type) # g,trialNum,target, repetition, iterationNum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### need to manually save it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_path = '/home/megsano/combined_sketch_features'\n",
    "layer_num = args.layer_ind\n",
    "data_type = 'sketch'\n",
    "layers = ['P1','P2','P3','P4','P5','FC6','FC7']\n",
    "out_path = os.path.join(feat_path,'FEATURES_{}_{}.npy'.format(layers[int(layer_num)], data_type))\n",
    "np.save(out_path, _Features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load features and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_feats = '/home/megsano/sketch_features/FEATURES_FC6_sketch.npy'\n",
    "path_to_meta = '/home/megsano/sketch_features/METADATA_sketch.csv'\n",
    "\n",
    "F = np.load(path_to_feats)\n",
    "M = pd.read_csv(path_to_meta)\n",
    "\n",
    "assert F.shape[0]==M.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## clean up M\n",
    "def clean_up_metadata(M):\n",
    "    M = M.rename(columns={'label':'path'})    \n",
    "    label = [i.split('/')[-1] for i in M.path.values]    \n",
    "    M = M.assign(label=pd.Series(label))\n",
    "    M = M.drop(columns=['Unnamed: 0'])\n",
    "    return M\n",
    "    \n",
    "M = clean_up_metadata(M) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
